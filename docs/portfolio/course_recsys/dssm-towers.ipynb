{
 "cells": [
  {
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:27.320249Z",
     "iopub.execute_input": "2025-01-08T14:51:27.320717Z",
     "iopub.status.idle": "2025-01-08T14:51:31.632634Z",
     "shell.execute_reply.started": "2025-01-08T14:51:27.320685Z",
     "shell.execute_reply": "2025-01-08T14:51:31.631040Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "!pip install pytorch-lightning -qqq",
   "execution_count": 70,
   "outputs": []
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:31.634520Z",
     "iopub.execute_input": "2025-01-08T14:51:31.634871Z",
     "iopub.status.idle": "2025-01-08T14:51:31.641623Z",
     "shell.execute_reply.started": "2025-01-08T14:51:31.634844Z",
     "shell.execute_reply": "2025-01-08T14:51:31.640272Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "import json\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom collections import Counter\nfrom random import randint, random\nfrom scipy.sparse import coo_matrix, hstack\nimport torch\nfrom pathlib import Path\nfrom tqdm import tqdm",
   "execution_count": 71,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Deep Similarity Similarity Model\n\n[![GitHub](https://img.shields.io/badge/Download-28343D?style=for-the-badge&logo=jupyter&logoColor=white)](https://shtrausslearning.github.io/notebooks/course_recsys/dssm-towers.ipynb)\n\n## **1 | Background**\n\nNotebook contents:\n\n- In this notebook, we'll implement a simple DSSM neural network model for recommendation systems.\n\n- We will be using embeddings for each unique user and item, group them together and pass them into linear layers, which will be our forward method for each individual 'tower'. The value in these embeddings is that they can be used in further models as features to create a ranker model.\n\n- Outputs of both 'towers' are multiplied together using a scalar product, to get the scores, similar to how it is done matrix factorisation approaches. These scores can be evaluated for all items and rearranged to get the top k recommendations for each user, based on the score value (section 9)\n\n- Training a neural network, we will be training the embedding layers in the context of a binary classification problem, in which we label the positive samples (items) as 1 and negative samples as 0. So we train a model that will be able to differentiate between positive and negative samples."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **2 | Read Dataset**\n\n- The dataset contains three data dataframes, user features, item features and the interaction details between user and item\n- Items in this dataset are movies and serials"
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:31.643793Z",
     "iopub.execute_input": "2025-01-08T14:51:31.644171Z",
     "iopub.status.idle": "2025-01-08T14:51:35.742594Z",
     "shell.execute_reply.started": "2025-01-08T14:51:31.644143Z",
     "shell.execute_reply": "2025-01-08T14:51:35.741575Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "users_df = pd.read_csv('/kaggle/input/kion-dataset/users.csv')  # user dataframe\nitems_df = pd.read_csv('/kaggle/input/kion-dataset/items.csv')\ninteractions_df = pd.read_csv('/kaggle/input/kion-dataset/interactions.csv') # user feature interaction dataframe",
   "execution_count": 72,
   "outputs": []
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:35.744055Z",
     "iopub.execute_input": "2025-01-08T14:51:35.744382Z",
     "iopub.status.idle": "2025-01-08T14:51:35.750738Z",
     "shell.execute_reply.started": "2025-01-08T14:51:35.744338Z",
     "shell.execute_reply": "2025-01-08T14:51:35.749546Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "# 5476251 user/item interactions\ninteractions_df.shape",
   "execution_count": 73,
   "outputs": [
    {
     "execution_count": 73,
     "output_type": "execute_result",
     "data": {
      "text/plain": "(5476251, 5)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **3 | Filter Interactions**\n\nWe need to filter items that have low interaction counts, as they probably won't be useful "
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:35.751786Z",
     "iopub.execute_input": "2025-01-08T14:51:35.752167Z",
     "iopub.status.idle": "2025-01-08T14:51:38.230270Z",
     "shell.execute_reply.started": "2025-01-08T14:51:35.752097Z",
     "shell.execute_reply": "2025-01-08T14:51:38.229279Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "# interactions 35% + only \n# user interactions must be more than 10\n# items must have been watched more than 10 times\n\nprint(f\"N users before: {interactions_df.user_id.nunique()}\")\nprint(f\"N items before: {interactions_df.item_id.nunique()}\\n\")\n\n# (1) пользователь посмотрел фильм менее чем на 35 процентов\ninteractions_df = interactions_df[interactions_df.watched_pct > 35]\n\n# соберем всех пользователей, которые посмотрели\n# больше 10 фильмов (можете выбрать другой порог)\nvalid_users = []\nc = Counter(interactions_df.user_id)\nfor user_id, entries in c.most_common():\n  if entries > 10:\n    valid_users.append(user_id)\n\n# и соберем все фильмы, которые посмотрели больше 10 пользователей\nvalid_items = []\nc = Counter(interactions_df.item_id)\nfor item_id, entries in c.most_common():\n  if entries > 10:\n    valid_items.append(item_id)\n\n# отбросим непопулярные фильмы и неактивных юзеров\ninteractions_df = interactions_df[interactions_df.user_id.isin(valid_users)]\ninteractions_df = interactions_df[interactions_df.item_id.isin(valid_items)]\n\nprint(f\"Number of users after filtration: {interactions_df.user_id.nunique()}\")\nprint(f\"Number of items after filtration: {interactions_df.item_id.nunique()}\")",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "text": "N users before: 962179\nN items before: 15706\n\nNumber of users after filtration: 54213\nNumber of items after filtration: 6140\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:38.231420Z",
     "iopub.execute_input": "2025-01-08T14:51:38.231796Z",
     "iopub.status.idle": "2025-01-08T14:51:38.700015Z",
     "shell.execute_reply.started": "2025-01-08T14:51:38.231758Z",
     "shell.execute_reply": "2025-01-08T14:51:38.698935Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "# Common Users & Items in interactions/User/Items after filtration\n\n# intersection between interactions & users; intersection between interactions & items \ncommon_users = set(interactions_df.user_id.unique()).intersection(set(users_df.user_id.unique()))\nprint(len(common_users))\n\ncommon_items = set(interactions_df.item_id.unique()).intersection(set(items_df.item_id.unique()))\nprint(len(common_items))\n\ninteractions_df = interactions_df[interactions_df.item_id.isin(common_items)]\ninteractions_df = interactions_df[interactions_df.user_id.isin(common_users)]\n\n# filtered items & users (we keep only users/items in interactions)\nitems_df_filtered = items_df[items_df.item_id.isin(interactions_df['item_id'].unique())].copy()\nusers_df_filtered = users_df[users_df.user_id.isin(interactions_df['user_id'].unique())].copy()",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "text": "44959\n6140\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **4 | Categorical Encoding**\n\nWe will use standard encoding for item & user features\n- `item_cat_feats` : item features to be used in model \n- `user_cat_feats` : user features to be used in model"
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:38.700996Z",
     "iopub.execute_input": "2025-01-08T14:51:38.701304Z",
     "iopub.status.idle": "2025-01-08T14:51:38.740204Z",
     "shell.execute_reply.started": "2025-01-08T14:51:38.701278Z",
     "shell.execute_reply": "2025-01-08T14:51:38.739272Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "'''\n\nItem features which need to be converted\n\n'''\n\nitem_cat_feats = ['content_type', 'release_year',\n                  'for_kids', 'age_rating',\n                  'studios', 'countries', 'directors']\n\ndisplay(items_df_filtered[item_cat_feats].head())\n\nfor col in item_cat_feats:\n  items_df_filtered[col] = items_df_filtered[col].fillna('unknown')\n  items_df_filtered[f'{col}_encoded'] = items_df_filtered[col].astype('category').cat.codes",
   "execution_count": 76,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   content_type  release_year  for_kids  age_rating studios       countries  \\\n8          film        2018.0       NaN        16.0     NaN         Испания   \n10         film        2018.0       NaN        18.0     NaN  Великобритания   \n16         film        2019.0       NaN        18.0     NaN             США   \n20         film        2019.0       NaN         6.0     NaN             США   \n38         film        2004.0       NaN        12.0     NaN             США   \n\n                  directors  \n8             Асгар Фархади  \n10              Тревор Нанн  \n16  Бретт Пирс, Дрю Т. Пирс  \n20                      NaN  \n38               Дэвид Кепп  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content_type</th>\n      <th>release_year</th>\n      <th>for_kids</th>\n      <th>age_rating</th>\n      <th>studios</th>\n      <th>countries</th>\n      <th>directors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>film</td>\n      <td>2018.0</td>\n      <td>NaN</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>Испания</td>\n      <td>Асгар Фархади</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>film</td>\n      <td>2018.0</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>NaN</td>\n      <td>Великобритания</td>\n      <td>Тревор Нанн</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>film</td>\n      <td>2019.0</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>NaN</td>\n      <td>США</td>\n      <td>Бретт Пирс, Дрю Т. Пирс</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>film</td>\n      <td>2019.0</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>США</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>film</td>\n      <td>2004.0</td>\n      <td>NaN</td>\n      <td>12.0</td>\n      <td>NaN</td>\n      <td>США</td>\n      <td>Дэвид Кепп</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:38.742958Z",
     "iopub.execute_input": "2025-01-08T14:51:38.743269Z",
     "iopub.status.idle": "2025-01-08T14:51:38.782246Z",
     "shell.execute_reply.started": "2025-01-08T14:51:38.743243Z",
     "shell.execute_reply": "2025-01-08T14:51:38.781238Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "user_cat_feats = [\"age\", \"income\", \"sex\", \"kids_flg\"]\n\nfor col in user_cat_feats:\n  users_df_filtered[col] = users_df_filtered[col].fillna('unknown')\n  users_df_filtered[f'{col}_encoded'] = users_df_filtered[col].astype('category').cat.codes\n\nusers_df_filtered[user_cat_feats].head()",
   "execution_count": 77,
   "outputs": [
    {
     "execution_count": 77,
     "output_type": "execute_result",
     "data": {
      "text/plain": "            age        income sex  kids_flg\n24    age_35_44  income_20_40   Ж         1\n27    age_25_34  income_40_60   М         1\n66    age_25_34  income_20_40   М         0\n81    age_25_34  income_20_40   М         0\n136  age_65_inf  income_20_40   М         0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>income</th>\n      <th>sex</th>\n      <th>kids_flg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24</th>\n      <td>age_35_44</td>\n      <td>income_20_40</td>\n      <td>Ж</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>age_25_34</td>\n      <td>income_40_60</td>\n      <td>М</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>age_25_34</td>\n      <td>income_20_40</td>\n      <td>М</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>age_25_34</td>\n      <td>income_20_40</td>\n      <td>М</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>136</th>\n      <td>age_65_inf</td>\n      <td>income_20_40</td>\n      <td>М</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **5 | Normalise IDs**\n\n`user_id` & `item_id` are just numbers, lets create a mapper for new ids that start from 0"
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:38.784105Z",
     "iopub.execute_input": "2025-01-08T14:51:38.784437Z",
     "iopub.status.idle": "2025-01-08T14:51:38.884503Z",
     "shell.execute_reply.started": "2025-01-08T14:51:38.784411Z",
     "shell.execute_reply": "2025-01-08T14:51:38.883280Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "'''\n\nConvert item / user ids to new normalised numbering from 0...\n\n'''\n\n# converted in order from 0 for user/items\ninteractions_df[\"uid\"] = interactions_df[\"user_id\"].astype(\"category\")\ninteractions_df[\"uid\"] = interactions_df[\"uid\"].cat.codes\n\ninteractions_df[\"iid\"] = interactions_df[\"item_id\"].astype(\"category\")\ninteractions_df[\"iid\"] = interactions_df[\"iid\"].cat.codes\n\n# lets confirm they start from 0\nprint(sorted(interactions_df.iid.unique())[:5])\nprint(sorted(interactions_df.uid.unique())[:5])",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "text": "[0, 1, 2, 3, 4]\n[0, 1, 2, 3, 4]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:38.885575Z",
     "iopub.execute_input": "2025-01-08T14:51:38.885916Z",
     "iopub.status.idle": "2025-01-08T14:51:38.897398Z",
     "shell.execute_reply.started": "2025-01-08T14:51:38.885888Z",
     "shell.execute_reply": "2025-01-08T14:51:38.896377Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "interactions_df.head()",
   "execution_count": 79,
   "outputs": [
    {
     "execution_count": 79,
     "output_type": "execute_result",
     "data": {
      "text/plain": "    user_id  item_id last_watch_dt  total_dur  watched_pct    uid   iid\n0    176549     9506    2021-05-11       4250         72.0   7234  3500\n1    699317     1659    2021-05-29       8317        100.0  28657   594\n14     5324     8437    2021-04-18       6598         92.0    208  3084\n18   927973     9617    2021-06-19       8422        100.0  37990  3536\n20   896751     8081    2021-05-17       6358        100.0  36735  2953",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>last_watch_dt</th>\n      <th>total_dur</th>\n      <th>watched_pct</th>\n      <th>uid</th>\n      <th>iid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>176549</td>\n      <td>9506</td>\n      <td>2021-05-11</td>\n      <td>4250</td>\n      <td>72.0</td>\n      <td>7234</td>\n      <td>3500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>699317</td>\n      <td>1659</td>\n      <td>2021-05-29</td>\n      <td>8317</td>\n      <td>100.0</td>\n      <td>28657</td>\n      <td>594</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>5324</td>\n      <td>8437</td>\n      <td>2021-04-18</td>\n      <td>6598</td>\n      <td>92.0</td>\n      <td>208</td>\n      <td>3084</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>927973</td>\n      <td>9617</td>\n      <td>2021-06-19</td>\n      <td>8422</td>\n      <td>100.0</td>\n      <td>37990</td>\n      <td>3536</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>896751</td>\n      <td>8081</td>\n      <td>2021-05-17</td>\n      <td>6358</td>\n      <td>100.0</td>\n      <td>36735</td>\n      <td>2953</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:38.898617Z",
     "iopub.execute_input": "2025-01-08T14:51:38.898938Z",
     "iopub.status.idle": "2025-01-08T14:51:39.203191Z",
     "shell.execute_reply.started": "2025-01-08T14:51:38.898903Z",
     "shell.execute_reply": "2025-01-08T14:51:39.202225Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "# extract from interaction all mappers for items\niid_to_item_id = interactions_df[[\"iid\", \"item_id\"]].drop_duplicates().set_index(\"iid\").to_dict()[\"item_id\"]\nitem_id_to_iid = interactions_df[[\"iid\", \"item_id\"]].drop_duplicates().set_index(\"item_id\").to_dict()[\"iid\"]\n\n# extract from interaction all mappers for users\nuid_to_user_id = interactions_df[[\"uid\", \"user_id\"]].drop_duplicates().set_index(\"uid\").to_dict()[\"user_id\"]\nuser_id_to_uid = interactions_df[[\"uid\", \"user_id\"]].drop_duplicates().set_index(\"user_id\").to_dict()[\"uid\"]\n\n# add iid to item dataframe\nitems_df_filtered[\"iid\"] = items_df_filtered[\"item_id\"].apply(lambda x: item_id_to_iid[x])\nitems_df_filtered = items_df_filtered.set_index(\"iid\")\n\n# add uid to user dataframe\nusers_df_filtered[\"uid\"] = users_df_filtered[\"user_id\"].apply(lambda x: user_id_to_uid[x])\nusers_df_filtered = users_df_filtered.set_index(\"uid\")",
   "execution_count": 80,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **6 | Prepare Torch Dataset**\n\nUsing the interactions data, each row will have (user_id,item_id), from these ids, the user features for this user, and the film features they interacted with, as well as a random item features are returned"
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.204245Z",
     "iopub.execute_input": "2025-01-08T14:51:39.204511Z",
     "iopub.status.idle": "2025-01-08T14:51:39.212591Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.204488Z",
     "shell.execute_reply": "2025-01-08T14:51:39.211276Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "from torch.utils.data import Dataset, DataLoader\n\nSEED = 42\nclass TupleDataset(Dataset):\n\n  def __init__(self,\n               user_pos_pairs: np.ndarray, # two dimentional user/item interaction\n               user_features: pd.DataFrame, # numerical user features\n               item_features: pd.DataFrame, # item features\n               n_negatives: int = 1) -> None:\n\n    self.user_pos_pairs = user_pos_pairs   # user, item pair numpy matrix\n    self.user_features = user_features  # user feature dataframe\n    self.item_features = item_features  # item feature dataframe\n    self.all_items = item_features.index.values\n    self.rng = np.random.default_rng(SEED)\n    self.n_negatives = n_negatives\n\n  def __len__(self):\n    return len(self.user_pos_pairs)\n\n  def __getitem__(self, index):\n\n    # user value & user item value \n    user, pos = self.user_pos_pairs[index]\n\n    # for the user pick random item, it will be our negative\n    negative = self.rng.choice(self.all_items, size=self.n_negatives).item() \n\n    user_features = self.user_features.loc[user].to_dict()   # user features\n    pos_features = self.item_features.loc[pos].to_dict()     # positive item features\n    neg_features = self.item_features.loc[negative].to_dict() # random sample from user/item as negative sample(s)\n\n    return {\n                'user_features': user_features,\n                'pos_features': pos_features,\n                'neg_features': neg_features\n            }",
   "execution_count": 81,
   "outputs": []
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.213783Z",
     "iopub.execute_input": "2025-01-08T14:51:39.214106Z",
     "iopub.status.idle": "2025-01-08T14:51:39.234332Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.214071Z",
     "shell.execute_reply": "2025-01-08T14:51:39.233054Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "from pytorch_lightning import LightningDataModule\n\nclass DssmDataModule(LightningDataModule):\n\n  def __init__(self,\n               train_ds: TupleDataset,\n               train_batch_size: int = 1):\n\n    super().__init__()\n    self.train_ds = train_ds\n    self.train_batch_size = train_batch_size\n\n  def train_dataloader(self):\n    return DataLoader(self.train_ds,\n                      batch_size=self.train_batch_size)",
   "execution_count": 82,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **7 | Select Features**\n\nSelect a subset of user and item dataframes, selecting only the encoded columns"
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.235268Z",
     "iopub.execute_input": "2025-01-08T14:51:39.235568Z",
     "iopub.status.idle": "2025-01-08T14:51:39.251361Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.235543Z",
     "shell.execute_reply": "2025-01-08T14:51:39.250253Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "# user / item features dataframe \nuser_feature_cols = [f'{col}_encoded' for col in user_cat_feats] # user features column names\nitem_feature_cols = [f'{col}_encoded' for col in item_cat_feats] # item feature column names\n\nuser_features = users_df_filtered[user_feature_cols]\nitem_features = items_df_filtered[item_feature_cols]",
   "execution_count": 83,
   "outputs": []
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.252427Z",
     "iopub.execute_input": "2025-01-08T14:51:39.252729Z",
     "iopub.status.idle": "2025-01-08T14:51:39.278430Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.252702Z",
     "shell.execute_reply": "2025-01-08T14:51:39.277339Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "user_features.head()",
   "execution_count": 84,
   "outputs": [
    {
     "execution_count": 84,
     "output_type": "execute_result",
     "data": {
      "text/plain": "       age_encoded  income_encoded  sex_encoded  kids_flg_encoded\nuid                                                              \n11047            2               2            1                 1\n15756            1               3            2                 1\n8852             1               2            2                 0\n21134            1               2            2                 0\n33752            5               2            2                 0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age_encoded</th>\n      <th>income_encoded</th>\n      <th>sex_encoded</th>\n      <th>kids_flg_encoded</th>\n    </tr>\n    <tr>\n      <th>uid</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11047</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15756</th>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8852</th>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21134</th>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33752</th>\n      <td>5</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "User, item interaction matrix"
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.279481Z",
     "iopub.execute_input": "2025-01-08T14:51:39.279771Z",
     "iopub.status.idle": "2025-01-08T14:51:39.305020Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.279746Z",
     "shell.execute_reply": "2025-01-08T14:51:39.304024Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "# user / item interactions\npairs = interactions_df[['uid', 'iid']].values # user uid interacted with iid\npairs",
   "execution_count": 85,
   "outputs": [
    {
     "execution_count": 85,
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 7234,  3500],\n       [28657,   594],\n       [  208,  3084],\n       ...,\n       [17861,  4980],\n       [24986,  2581],\n       [15738,  6017]], dtype=int32)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <b>8 | Group User/Item Data into Dataset</b>\n\na) Dataset containing grouped positive item features, negative item festures and its user features"
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.306250Z",
     "iopub.execute_input": "2025-01-08T14:51:39.306606Z",
     "iopub.status.idle": "2025-01-08T14:51:39.316318Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.306576Z",
     "shell.execute_reply": "2025-01-08T14:51:39.315414Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "# create a dictionary of features for \n# creates positive, negative feature samples\n\ntrain_ds = TupleDataset(user_pos_pairs=pairs,\n                        user_features=user_features,\n                        item_features=item_features)",
   "execution_count": 86,
   "outputs": []
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.317313Z",
     "iopub.execute_input": "2025-01-08T14:51:39.317591Z",
     "iopub.status.idle": "2025-01-08T14:51:39.343635Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.317565Z",
     "shell.execute_reply": "2025-01-08T14:51:39.342539Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "# example of data from TupleDataset\nimport pprint; pprint.pprint(train_ds[0])",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "text": "{'neg_features': {'age_rating_encoded': 2,\n                  'content_type_encoded': 1,\n                  'countries_encoded': 459,\n                  'directors_encoded': 1626,\n                  'for_kids_encoded': 2,\n                  'release_year_encoded': 87,\n                  'studios_encoded': 24},\n 'pos_features': {'age_rating_encoded': 0,\n                  'content_type_encoded': 0,\n                  'countries_encoded': 322,\n                  'directors_encoded': 1946,\n                  'for_kids_encoded': 2,\n                  'release_year_encoded': 83,\n                  'studios_encoded': 24},\n 'user_features': {'age_encoded': 2,\n                   'income_encoded': 3,\n                   'kids_flg_encoded': 0,\n                   'sex_encoded': 2}}\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "b) Create batched dataset"
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.344736Z",
     "iopub.execute_input": "2025-01-08T14:51:39.345074Z",
     "iopub.status.idle": "2025-01-08T14:51:39.349977Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.345047Z",
     "shell.execute_reply": "2025-01-08T14:51:39.348712Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "batch_size = 4\ndm = DssmDataModule(train_ds=train_ds,           # created dataset\n                    train_batch_size=batch_size) # size of group",
   "execution_count": 88,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sample of batch data"
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T15:28:00.991737Z",
     "iopub.execute_input": "2025-01-08T15:28:00.992117Z",
     "iopub.status.idle": "2025-01-08T15:28:01.023477Z",
     "shell.execute_reply.started": "2025-01-08T15:28:00.992090Z",
     "shell.execute_reply": "2025-01-08T15:28:01.022256Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "# next batch data \n# next(iter(dm.train_dataloader())).keys()\nbatch = next(iter(dm.train_dataloader()))\npprint.pprint(batch)",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "text": "{'neg_features': {'age_rating_encoded': tensor([2, 2, 4, 0]),\n                  'content_type_encoded': tensor([1, 0, 0, 0]),\n                  'countries_encoded': tensor([294, 332, 294, 322]),\n                  'directors_encoded': tensor([ 618, 2630,  208, 3926]),\n                  'for_kids_encoded': tensor([2, 2, 2, 2]),\n                  'release_year_encoded': tensor([54, 90, 82, 73]),\n                  'studios_encoded': tensor([24, 24, 24, 24])},\n 'pos_features': {'age_rating_encoded': tensor([0, 1, 3, 2]),\n                  'content_type_encoded': tensor([0, 0, 0, 0]),\n                  'countries_encoded': tensor([322, 294, 323, 322]),\n                  'directors_encoded': tensor([1946, 1749,  371,  559]),\n                  'for_kids_encoded': tensor([2, 2, 2, 2]),\n                  'release_year_encoded': tensor([83, 84, 89, 86]),\n                  'studios_encoded': tensor([24, 24, 24, 24])},\n 'user_features': {'age_encoded': tensor([2, 2, 0, 1]),\n                   'income_encoded': tensor([3, 3, 2, 2]),\n                   'kids_flg_encoded': tensor([0, 0, 0, 0]),\n                   'sex_encoded': tensor([2, 2, 1, 2])}}\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set parameters for embedding matrices "
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.370656Z",
     "iopub.execute_input": "2025-01-08T14:51:39.371384Z",
     "iopub.status.idle": "2025-01-08T14:51:39.380016Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.371342Z",
     "shell.execute_reply": "2025-01-08T14:51:39.378834Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "N_FACTORS = 64  # number of factors in each embedding\nCAT_EMBEDDING_DIM = 16 \n\n# в датасетах есть столбец user_id/item_id, помним, что он не является фичей для обучения!\nITEM_MODEL_SHAPE = len(item_feature_cols) * CAT_EMBEDDING_DIM\nUSER_META_MODEL_SHAPE = len(user_feature_cols) * CAT_EMBEDDING_DIM\n\n# USER_INTERACTION_MODEL_SHAPE = (interactions_vec.shape[1], )\nprint(f\"N_FACTORS: {N_FACTORS}\")\nprint(f\"ITEM_MODEL_SHAPE: {ITEM_MODEL_SHAPE}\")\nprint(f\"USER_META_MODEL_SHAPE: {USER_META_MODEL_SHAPE}\")",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "text": "N_FACTORS: 64\nITEM_MODEL_SHAPE: 112\nUSER_META_MODEL_SHAPE: 64\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.381393Z",
     "iopub.execute_input": "2025-01-08T14:51:39.381800Z",
     "iopub.status.idle": "2025-01-08T14:51:39.400429Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.381761Z",
     "shell.execute_reply": "2025-01-08T14:51:39.399048Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "import torch.nn as nn\n\n# inividual tower part of model \nclass DssmTower(nn.Module):\n\n  def __init__(self,\n               feat_vocab_sizes: dict[str, int],\n               cat_feat_emb_dim: int,\n               hidden_dim: int,\n               out_dim: int):\n\n    super().__init__()\n\n    # embeddings for each unique value in user / item\n    self.embedding = nn.ModuleDict({\n        cat_feat: nn.Embedding(cat_feat_vocab_size, cat_feat_emb_dim) for cat_feat, cat_feat_vocab_size in feat_vocab_sizes.items()\n    })\n    self.features = list(feat_vocab_sizes.keys())\n    self.layer_1 = nn.Linear(cat_feat_emb_dim * len(feat_vocab_sizes), hidden_dim)\n    self.layer_2 = nn.Linear(hidden_dim, hidden_dim)\n    self.layer_3 = nn.Linear(hidden_dim, out_dim)\n\n  def forward(self, batch):\n\n    # concatenate all embeddings (they have same embedding dimenion)\n    embeddings = []\n    for feature in self.features:\n      feature_embedding = self.embedding[feature](batch[feature])\n      embeddings.append(feature_embedding)\n    embedding = torch.cat(embeddings, dim=1)\n\n    layer_1 = self.layer_1(embedding)\n    layer_2 = self.layer_2(layer_1)\n    layer_2 += layer_1\n    output = self.layer_3(layer_2)\n    return output\n",
   "execution_count": 91,
   "outputs": []
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.404384Z",
     "iopub.execute_input": "2025-01-08T14:51:39.404758Z",
     "iopub.status.idle": "2025-01-08T14:51:39.426174Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.404726Z",
     "shell.execute_reply": "2025-01-08T14:51:39.425091Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "# number of unique elements in column \nuser_feat_vocab_size = dict()\nfor col in user_features.columns:\n  user_feat_vocab_size[col] = user_features[col].nunique()\n\nuser_feat_vocab_size",
   "execution_count": 92,
   "outputs": [
    {
     "execution_count": 92,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'age_encoded': 7,\n 'income_encoded': 7,\n 'sex_encoded': 3,\n 'kids_flg_encoded': 2}"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.427884Z",
     "iopub.execute_input": "2025-01-08T14:51:39.428258Z",
     "iopub.status.idle": "2025-01-08T14:51:39.444708Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.428230Z",
     "shell.execute_reply": "2025-01-08T14:51:39.443556Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "# number of unique elements in column \nitem_feat_vocab_size = dict()\nfor col in item_features.columns:\n  item_feat_vocab_size[col] = item_features[col].nunique()\n\nitem_feat_vocab_size",
   "execution_count": 93,
   "outputs": [
    {
     "execution_count": 93,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'content_type_encoded': 2,\n 'release_year_encoded': 92,\n 'for_kids_encoded': 3,\n 'age_rating_encoded': 6,\n 'studios_encoded': 28,\n 'countries_encoded': 535,\n 'directors_encoded': 4041}"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.446100Z",
     "iopub.execute_input": "2025-01-08T14:51:39.446536Z",
     "iopub.status.idle": "2025-01-08T14:51:39.462448Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.446497Z",
     "shell.execute_reply": "2025-01-08T14:51:39.461289Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "from pytorch_lightning import LightningModule\nfrom torch.optim import Adam\n\n# Lightning Module\nclass DssmLitModule(LightningModule):\n    \n  def __init__(self, user_tower: DssmTower, \n               item_tower: DssmTower, \n               optim_hparams: dict):\n      \n    super().__init__()\n    self.user_tower = user_tower  # neural network for users\n    self.item_tower = item_tower  # neural network for items\n    self.optim_hparams = optim_hparams\n    self.loss = torch.nn.BCEWithLogitsLoss()\n\n  def training_step(self, batch, batch_idx):\n\n    # extract feature data from dictionary (dictionary format)\n    user_feats = batch['user_features'] # feature : tensor values of batch\n    pos_feats = batch['pos_features'] # ''\n    neg_feats = batch['neg_features'] # ''\n      \n    # for each user/item input into each tower & activate (forward method)\n    # for each batch item tower, one logits item for usrfeat/posfeat/negfeat x batch number\n    user_embs = self.user_tower(user_feats) # (batch_size x out_dim)\n    pos_embs = self.item_tower(pos_feats) # (batch_size x out_dim)\n    neg_embs = self.item_tower(neg_feats) # (batch_size x out_dim)\n\n    # (batch_size x 2 x out_dim) -> for both positive / negative samples\n    item_embs = torch.cat((pos_embs.unsqueeze(1), \n                           neg_embs.unsqueeze(1)), dim=1) \n\n    # dot scores for both positive & negative samples\n    dot_scores = (user_embs.unsqueeze(1) @ item_embs.transpose(1, 2)).squeeze()  \n\n    # everything in second dimension is negative sample (item) (label = 0)\n    labels = torch.zeros_like(dot_scores) # (zeros of shape 2 x out_dims)\n    labels[:, 0] = 1 # everything in first dimension is positive sample (item) (label = 1)\n\n    loss = self.loss(dot_scores, labels)  # loss per batch\n    self.log('train_loss',\n             loss.item(), \n             on_epoch=True, \n             on_step=True, \n             prog_bar=True)\n\n    return loss\n\n  def configure_optimizers(self):\n    return Adam(self.parameters(), **self.optim_hparams)",
   "execution_count": 94,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define the tower parts of the neural network. In our model, we will be training two towers, one for user embedding features, and another for the item embedding."
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.463497Z",
     "iopub.execute_input": "2025-01-08T14:51:39.463832Z",
     "iopub.status.idle": "2025-01-08T14:51:39.484634Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.463807Z",
     "shell.execute_reply": "2025-01-08T14:51:39.483492Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "# user tower of nn (input into dssm_module)\nuser_tower = DssmTower(\n                        feat_vocab_sizes=user_feat_vocab_size,\n                        cat_feat_emb_dim=CAT_EMBEDDING_DIM,\n                        hidden_dim=64,\n                        out_dim=64 # output dimension for each tower\n                        )\n\n# item tower segment of nn (input into dssm_module)\nitem_tower = DssmTower(\n                        feat_vocab_sizes=item_feat_vocab_size,\n                        cat_feat_emb_dim=CAT_EMBEDDING_DIM,\n                        hidden_dim=64,\n                        out_dim=64 # output dimension for each tower\n                        )\n\n# entire network using Lightning Module\ndssm_module = DssmLitModule(user_tower, \n                            item_tower, \n                            optim_hparams={'lr': 1e-3})",
   "execution_count": 95,
   "outputs": []
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.498503Z",
     "iopub.execute_input": "2025-01-08T14:51:39.498824Z",
     "iopub.status.idle": "2025-01-08T14:51:39.514661Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.498784Z",
     "shell.execute_reply": "2025-01-08T14:51:39.513275Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "# (user_tower) 16 x 4 -> 64\n# (item_tower) 16 x 7 -> 112 features",
   "execution_count": 97,
   "outputs": []
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.550990Z",
     "iopub.execute_input": "2025-01-08T14:51:39.551290Z",
     "iopub.status.idle": "2025-01-08T14:51:39.559670Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.551265Z",
     "shell.execute_reply": "2025-01-08T14:51:39.558629Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "# one batch prediction\nwith torch.no_grad():\n    print(dssm_module.training_step(batch, 0))\n\n# # dot scores for batch 4\n# tensor([[-0.1367, -0.7055],\n#         [ 0.8072,  1.3774],\n#         [ 0.4891,  0.5485],\n#         [ 1.1119,  1.1324]])\n\n# # labels \n# tensor([[1., 0.],\n#         [1., 0.],\n#         [1., 0.],\n#         [1., 0.]])\n\n# # loss per batch\n# tensor(0.7894)",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "text": "tensor(1.1566)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **9 | Train model**\n\nIn this example, we will train only one epoch, just as an example"
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.560716Z",
     "iopub.execute_input": "2025-01-08T14:51:39.561054Z",
     "iopub.status.idle": "2025-01-08T14:51:39.571276Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.561027Z",
     "shell.execute_reply": "2025-01-08T14:51:39.570055Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "from pytorch_lightning import Trainer\n\n# trainer = Trainer(max_epochs=1, enable_checkpointing=False)\n# trainer.fit(dssm_module, dm)",
   "execution_count": 100,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **10 | Inference Example**\n\n- Once we have a trained model, the class `dssm_module` contains the updated model weights\n- We can for a particular user and film combination, evaluate the score. We could repeat this process for all the items, and find he top k films, which we can recommend the user "
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.572345Z",
     "iopub.execute_input": "2025-01-08T14:51:39.572692Z",
     "iopub.status.idle": "2025-01-08T14:51:39.602294Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.572657Z",
     "shell.execute_reply": "2025-01-08T14:51:39.601162Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "# select user\n\n# берем рандомного юзера\nrand_uid = np.random.choice(list(user_features.index))\n\n# получаем фичи юзера и вектор его просмотров айтемов\nrand_uid_feats = user_features.loc[rand_uid].to_dict()\n\n# select item\n\n# берем рандомный айтем\nrand_iid = np.random.choice(list(item_features.index))\n# получаем фичи айтема\nrand_iid_feats = item_features.loc[rand_iid].to_dict()\n\nprint('random user',rand_uid)\nprint('random user features')\npprint.pprint(rand_uid_feats)\nprint('')\nprint('random item',rand_iid)\nprint('random item features')\npprint.pprint(rand_iid_feats)",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "text": "random user 40981\nrandom user features\n{'age_encoded': 1, 'income_encoded': 3, 'kids_flg_encoded': 0, 'sex_encoded': 1}\n\nrandom item 5654\nrandom item features\n{'age_rating_encoded': 3,\n 'content_type_encoded': 0,\n 'countries_encoded': 322,\n 'directors_encoded': 3012,\n 'for_kids_encoded': 2,\n 'release_year_encoded': 70,\n 'studios_encoded': 24}\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T14:51:39.603400Z",
     "iopub.execute_input": "2025-01-08T14:51:39.603699Z",
     "iopub.status.idle": "2025-01-08T14:51:39.624849Z",
     "shell.execute_reply.started": "2025-01-08T14:51:39.603673Z",
     "shell.execute_reply": "2025-01-08T14:51:39.623762Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "# create a tensor\nfor key in rand_uid_feats:\n    rand_uid_feats[key] = torch.tensor([rand_uid_feats[key]])\nfor key in rand_iid_feats:\n    rand_iid_feats[key] = torch.tensor([rand_iid_feats[key]])\n\npprint.pprint(rand_uid_feats)",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "text": "{'age_encoded': tensor([1]),\n 'income_encoded': tensor([3]),\n 'kids_flg_encoded': tensor([0]),\n 'sex_encoded': tensor([1])}\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using the tower classes, calculate the forward pass prediction using existing model weights"
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T15:39:58.372105Z",
     "iopub.execute_input": "2025-01-08T15:39:58.372529Z",
     "iopub.status.idle": "2025-01-08T15:39:58.380223Z",
     "shell.execute_reply.started": "2025-01-08T15:39:58.372500Z",
     "shell.execute_reply": "2025-01-08T15:39:58.379241Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "dssm_module.user_tower(rand_uid_feats).size()",
   "execution_count": 107,
   "outputs": [
    {
     "execution_count": 107,
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([1, 64])"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T15:41:12.650731Z",
     "iopub.execute_input": "2025-01-08T15:41:12.651141Z",
     "iopub.status.idle": "2025-01-08T15:41:12.659247Z",
     "shell.execute_reply.started": "2025-01-08T15:41:12.651092Z",
     "shell.execute_reply": "2025-01-08T15:41:12.657781Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "dssm_module.item_tower(rand_iid_feats).size()",
   "execution_count": 109,
   "outputs": [
    {
     "execution_count": 109,
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([1, 64])"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Calculate the dot scores for user/item combination, this can be done a couple of ways"
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T15:41:18.994281Z",
     "iopub.execute_input": "2025-01-08T15:41:18.994654Z",
     "iopub.status.idle": "2025-01-08T15:41:19.003268Z",
     "shell.execute_reply.started": "2025-01-08T15:41:18.994627Z",
     "shell.execute_reply": "2025-01-08T15:41:19.002223Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "(dssm_module.user_tower(rand_uid_feats) * dssm_module.item_tower(rand_iid_feats)).sum()",
   "execution_count": 110,
   "outputs": [
    {
     "execution_count": 110,
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(-2.4099, grad_fn=<SumBackward0>)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-08T15:44:03.870570Z",
     "iopub.execute_input": "2025-01-08T15:44:03.870919Z",
     "iopub.status.idle": "2025-01-08T15:44:03.880335Z",
     "shell.execute_reply.started": "2025-01-08T15:44:03.870882Z",
     "shell.execute_reply": "2025-01-08T15:44:03.879256Z"
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": "dssm_module.user_tower(rand_uid_feats) @ dssm_module.item_tower(rand_iid_feats).transpose(0,1)",
   "execution_count": 113,
   "outputs": [
    {
     "execution_count": 113,
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[-2.4099]], grad_fn=<MmBackward0>)"
     },
     "metadata": {}
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 10349911,
     "sourceType": "datasetVersion",
     "datasetId": 6409061
    }
   ],
   "dockerImageVersionId": 30822,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}