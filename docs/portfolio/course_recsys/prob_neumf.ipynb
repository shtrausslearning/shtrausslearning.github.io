{
 "cells": [
  {
   "metadata": {},
   "id": "59001639",
   "cell_type": "markdown",
   "source": "# NeuMF\n\n[![GitHub](https://img.shields.io/badge/Download-28343D?style=for-the-badge&logo=jupyter&logoColor=white)](https://shtrausslearning.github.io/notebooks/course_recsys/prob_neumf.ipynb)"
  },
  {
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-29T09:09:02.222683Z",
     "iopub.status.busy": "2024-10-29T09:09:02.222276Z",
     "iopub.status.idle": "2024-10-29T09:09:06.577544Z",
     "shell.execute_reply": "2024-10-29T09:09:06.576754Z"
    },
    "papermill": {
     "duration": 4.362695,
     "end_time": "2024-10-29T09:09:06.579896",
     "exception": false,
     "start_time": "2024-10-29T09:09:02.217201",
     "status": "completed"
    },
    "tags": [],
    "trusted": false
   },
   "id": "b11f1de5",
   "cell_type": "code",
   "source": "import numpy as np \nimport pandas as pd \nimport scipy.sparse as sp\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom dataclasses import dataclass\nimport os\nimport time\nimport torch\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torch.backends.cudnn as cudnn\n\n@dataclass\nclass Config:\n\n    train_rating = '/kaggle/input/ratings-test/ml-1m.train.rating'\n    test_negative = '/kaggle/input/ratings-test/ml-1m.test.negative'\n    model_path = '/kaggle/working/model/'\n    out = True\n    \n    model : str\n    batch_size : int = 256\n    factor_num : int = 32\n    num_layers : int = 3\n    test_num_ng : int = 99\n    num_ng : int = 4\n    dropout : float = 0.0\n    lr : float = 0.001\n    epochs : int = 20\n    top_k = 10\n    gpu = \"0\"\n    \nconfig = Config(model='NeuMF-end')\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu\ncudnn.benchmark = True",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T09:09:06.588362Z",
     "iopub.status.busy": "2024-10-29T09:09:06.587719Z",
     "iopub.status.idle": "2024-10-29T09:09:06.609602Z",
     "shell.execute_reply": "2024-10-29T09:09:06.608898Z"
    },
    "papermill": {
     "duration": 0.027881,
     "end_time": "2024-10-29T09:09:06.611448",
     "exception": false,
     "start_time": "2024-10-29T09:09:06.583567",
     "status": "completed"
    },
    "tags": [],
    "trusted": false
   },
   "id": "89b02ade",
   "cell_type": "code",
   "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F \n\nclass NCF(nn.Module):\n\tdef __init__(self, user_num, item_num, factor_num, num_layers,\n\t\t\t\t\tdropout, model, GMF_model=None, MLP_model=None):\n\t\tsuper(NCF, self).__init__()\n\t\t\"\"\"\n\t\tuser_num: number of users;\n\t\titem_num: number of items;\n\t\tfactor_num: number of predictive factors;\n\t\tnum_layers: the number of layers in MLP model;\n\t\tdropout: dropout rate between fully connected layers;\n\t\tmodel: 'MLP', 'GMF', 'NeuMF-end', and 'NeuMF-pre';\n\t\tGMF_model: pre-trained GMF weights;\n\t\tMLP_model: pre-trained MLP weights.\n\t\t\"\"\"\t\t\n\t\tself.dropout = dropout\n\t\tself.model = model\n\t\tself.GMF_model = GMF_model\n\t\tself.MLP_model = MLP_model\n\n\t\tself.embed_user_GMF = nn.Embedding(user_num, factor_num)\n\t\tself.embed_item_GMF = nn.Embedding(item_num, factor_num)\n\t\tself.embed_user_MLP = nn.Embedding(\n\t\t\t\tuser_num, factor_num * (2 ** (num_layers - 1)))\n\t\tself.embed_item_MLP = nn.Embedding(\n\t\t\t\titem_num, factor_num * (2 ** (num_layers - 1)))\n\n\t\tMLP_modules = []\n\t\tfor i in range(num_layers):\n\t\t\tinput_size = factor_num * (2 ** (num_layers - i))\n\t\t\tMLP_modules.append(nn.Dropout(p=self.dropout))\n\t\t\tMLP_modules.append(nn.Linear(input_size, input_size//2))\n\t\t\tMLP_modules.append(nn.ReLU())\n\t\tself.MLP_layers = nn.Sequential(*MLP_modules)\n\n\t\tif self.model in ['MLP', 'GMF']:\n\t\t\tpredict_size = factor_num \n\t\telse:\n\t\t\tpredict_size = factor_num * 2\n\t\tself.predict_layer = nn.Linear(predict_size, 1)\n\t\tself._init_weight_()\n\n\tdef _init_weight_(self):\n\t\t\n\t\tif not self.model == 'NeuMF-pre':\n\t\t\tnn.init.normal_(self.embed_user_GMF.weight, std=0.01)\n\t\t\tnn.init.normal_(self.embed_user_MLP.weight, std=0.01)\n\t\t\tnn.init.normal_(self.embed_item_GMF.weight, std=0.01)\n\t\t\tnn.init.normal_(self.embed_item_MLP.weight, std=0.01)\n\n\t\t\tfor m in self.MLP_layers:\n\t\t\t\tif isinstance(m, nn.Linear):\n\t\t\t\t\tnn.init.xavier_uniform_(m.weight)\n\t\t\tnn.init.kaiming_uniform_(self.predict_layer.weight, \n\t\t\t\t\t\t\t\t\ta=1, nonlinearity='sigmoid')\n\n\t\t\tfor m in self.modules():\n\t\t\t\tif isinstance(m, nn.Linear) and m.bias is not None:\n\t\t\t\t\tm.bias.data.zero_()\n\t\telse:\n\t\t\t# embedding layers\n\t\t\tself.embed_user_GMF.weight.data.copy_(\n\t\t\t\t\t\t\tself.GMF_model.embed_user_GMF.weight)\n\t\t\tself.embed_item_GMF.weight.data.copy_(\n\t\t\t\t\t\t\tself.GMF_model.embed_item_GMF.weight)\n\t\t\tself.embed_user_MLP.weight.data.copy_(\n\t\t\t\t\t\t\tself.MLP_model.embed_user_MLP.weight)\n\t\t\tself.embed_item_MLP.weight.data.copy_(\n\t\t\t\t\t\t\tself.MLP_model.embed_item_MLP.weight)\n\n\t\t\t# mlp layers\n\t\t\tfor (m1, m2) in zip(\n\t\t\t\tself.MLP_layers, self.MLP_model.MLP_layers):\n\t\t\t\tif isinstance(m1, nn.Linear) and isinstance(m2, nn.Linear):\n\t\t\t\t\tm1.weight.data.copy_(m2.weight)\n\t\t\t\t\tm1.bias.data.copy_(m2.bias)\n\n\t\t\t# predict layers\n\t\t\tpredict_weight = torch.cat([\n\t\t\t\tself.GMF_model.predict_layer.weight, \n\t\t\t\tself.MLP_model.predict_layer.weight], dim=1)\n\t\t\tprecit_bias = self.GMF_model.predict_layer.bias + \\\n\t\t\t\t\t\tself.MLP_model.predict_layer.bias\n\n\t\t\tself.predict_layer.weight.data.copy_(0.5 * predict_weight)\n\t\t\tself.predict_layer.bias.data.copy_(0.5 * precit_bias)\n\n\tdef forward(self, user, item):\n\t\tif not self.model == 'MLP':\n\t\t\tembed_user_GMF = self.embed_user_GMF(user)\n\t\t\tembed_item_GMF = self.embed_item_GMF(item)\n\t\t\toutput_GMF = embed_user_GMF * embed_item_GMF\n\t\tif not self.model == 'GMF':\n\t\t\tembed_user_MLP = self.embed_user_MLP(user)\n\t\t\tembed_item_MLP = self.embed_item_MLP(item)\n\t\t\tinteraction = torch.cat((embed_user_MLP, embed_item_MLP), -1)\n\t\t\toutput_MLP = self.MLP_layers(interaction)\n\n\t\tif self.model == 'GMF':\n\t\t\tconcat = output_GMF\n\t\telif self.model == 'MLP':\n\t\t\tconcat = output_MLP\n\t\telse:\n\t\t\tconcat = torch.cat((output_GMF, output_MLP), -1)\n\n\t\tprediction = self.predict_layer(concat)\n\t\treturn prediction.view(-1)",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T09:09:06.618456Z",
     "iopub.status.busy": "2024-10-29T09:09:06.618196Z",
     "iopub.status.idle": "2024-10-29T09:09:06.626631Z",
     "shell.execute_reply": "2024-10-29T09:09:06.625702Z"
    },
    "papermill": {
     "duration": 0.014474,
     "end_time": "2024-10-29T09:09:06.628885",
     "exception": false,
     "start_time": "2024-10-29T09:09:06.614411",
     "status": "completed"
    },
    "tags": [],
    "trusted": false
   },
   "id": "43c49392",
   "cell_type": "code",
   "source": "def hit(gt_item, pred_items):\n\tif gt_item in pred_items:\n\t\treturn 1\n\treturn 0\n\ndef ndcg(gt_item, pred_items):\n\tif gt_item in pred_items:\n\t\tindex = pred_items.index(gt_item)\n\t\treturn np.reciprocal(np.log2(index+2))\n\treturn 0\n\ndef metrics(model, test_loader, top_k):\n\tHR, NDCG = [], []\n\n\tfor user, item, label in test_loader:\n\t\tuser = user.cuda()\n\t\titem = item.cuda()\n\n\t\tpredictions = model(user, item)\n\t\t_, indices = torch.topk(predictions, top_k)\n\t\trecommends = torch.take(\n\t\t\t\titem, indices).cpu().numpy().tolist()\n\n\t\tgt_item = item[0].item()\n\t\tHR.append(hit(gt_item, recommends))\n\t\tNDCG.append(ndcg(gt_item, recommends))\n\n\treturn np.mean(HR), np.mean(NDCG)",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T09:09:06.636797Z",
     "iopub.status.busy": "2024-10-29T09:09:06.636506Z",
     "iopub.status.idle": "2024-10-29T09:09:06.647894Z",
     "shell.execute_reply": "2024-10-29T09:09:06.646916Z"
    },
    "papermill": {
     "duration": 0.018133,
     "end_time": "2024-10-29T09:09:06.650023",
     "exception": false,
     "start_time": "2024-10-29T09:09:06.631890",
     "status": "completed"
    },
    "tags": [],
    "trusted": false
   },
   "id": "106503ee",
   "cell_type": "code",
   "source": "def load_all(test_num=100):\n\n\t# load training data (positive samples only)\n\ttrain_data = pd.read_csv(\n\t\tconfig.train_rating, \n\t\tsep='\\t', header=None, names=['user', 'item'], \n\t\tusecols=[0, 1], dtype={0: np.int32, 1: np.int32})\n\n\tuser_num = train_data['user'].max() + 1\n\titem_num = train_data['item'].max() + 1\n\ttrain_data = train_data.values.tolist()\n\n\t# load user/film rating combinations as a dok matrix\n\ttrain_mat = sp.dok_matrix((user_num, item_num), dtype=np.float32)\n\tfor x in train_data:\n\t\ttrain_mat[x[0], x[1]] = 1.0\n\n\t# load test data (positive & 99 negative samples) \n\ttest_data = []\n\twith open(config.test_negative, 'r') as fd:\n\t\tline = fd.readline()\n\t\twhile line != None and line != '':\n\t\t\tarr = line.split('\\t')\n\t\t\tu = eval(arr[0])[0]\n\t\t\ttest_data.append([u, eval(arr[0])[1]])\n\t\t\tfor i in arr[1:]:\n\t\t\t\ttest_data.append([u, int(i)])\n\t\t\tline = fd.readline()\n\treturn train_data, test_data, user_num, item_num, train_mat",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T09:09:06.659346Z",
     "iopub.status.busy": "2024-10-29T09:09:06.659075Z",
     "iopub.status.idle": "2024-10-29T09:09:06.671660Z",
     "shell.execute_reply": "2024-10-29T09:09:06.669878Z"
    },
    "papermill": {
     "duration": 0.020445,
     "end_time": "2024-10-29T09:09:06.674523",
     "exception": false,
     "start_time": "2024-10-29T09:09:06.654078",
     "status": "completed"
    },
    "tags": [],
    "trusted": false
   },
   "id": "85ff6de1",
   "cell_type": "code",
   "source": "class NCFData(data.Dataset):\n    \n\tdef __init__(self,\n\t\t\t\tfeatures, \n\t\t\t\tnum_item, \n\t\t\t\ttrain_mat=None, \n\t\t\t\tnum_ng=0, \n\t\t\t\tis_training=None):\n\t\t\t\t\n\t\tsuper(NCFData, self).__init__()\n\t\tself.features_ps = features\n\t\tself.num_item = num_item\n\t\tself.train_mat = train_mat\n\t\tself.num_ng = num_ng\n\t\tself.is_training = is_training\n\t\tself.labels = [0 for _ in range(len(features))]\n\n\t# add negative samples to the positive samples (train)\n\tdef ng_sample(self):\n\t\tassert self.is_training, 'no need to sampling when testing'\n\n\t\tself.features_ng = []\n\t\tfor x in self.features_ps:\n\t\t\tu = x[0]\n\t\t\tfor t in range(self.num_ng):\n\t\t\t\tj = np.random.randint(self.num_item)\n\t\t\t\twhile (u, j) in self.train_mat:\n\t\t\t\t\tj = np.random.randint(self.num_item)\n\t\t\t\tself.features_ng.append([u, j])\n\n\t\tlabels_ps = [1 for _ in range(len(self.features_ps))]\n\t\tlabels_ng = [0 for _ in range(len(self.features_ng))]\n\n\t\tself.features_fill = self.features_ps + self.features_ng\n\t\tself.labels_fill = labels_ps + labels_ng\n\n\tdef __len__(self):\n\t\treturn (self.num_ng + 1) * len(self.labels)\n\n\t# get items during training\n\tdef __getitem__(self, idx):\n\t\t\n\t\tfeatures = self.features_fill if self.is_training \\\n\t\t\t\t\telse self.features_ps\n\t\tlabels = self.labels_fill if self.is_training \\\n\t\t\t\t\telse self.labels\n\n\t\tuser = features[idx][0]\n\t\titem = features[idx][1]\n\t\tlabel = labels[idx]\n\t\treturn user, item ,label",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T09:09:06.682151Z",
     "iopub.status.busy": "2024-10-29T09:09:06.681834Z",
     "iopub.status.idle": "2024-10-29T09:09:26.606020Z",
     "shell.execute_reply": "2024-10-29T09:09:26.605224Z"
    },
    "papermill": {
     "duration": 19.930568,
     "end_time": "2024-10-29T09:09:26.608402",
     "exception": false,
     "start_time": "2024-10-29T09:09:06.677834",
     "status": "completed"
    },
    "tags": [],
    "trusted": false
   },
   "id": "aeb6a9d5",
   "cell_type": "code",
   "source": "train_data, test_data, user_num ,item_num, train_mat = load_all()\n\n# construct the train and test datasets\ntrain_dataset = NCFData(train_data,\n\t\t\t\t\t\titem_num, \n\t\t\t\t\t\ttrain_mat, \n\t\t\t\t\t\tconfig.num_ng,\n\t\t\t\t\t\tTrue)\n\t\t\t\t\t\t\ntest_dataset = NCFData(test_data, \n\t\t\t\t\t\titem_num,\n\t\t\t\t\t\ttrain_mat,\n\t\t\t\t\t\t0, \n\t\t\t\t\t\tFalse)\n\ntrain_loader = data.DataLoader(train_dataset,\n\t\t\t\t\t\t\t\tbatch_size=config.batch_size, \n\t\t\t\t\t\t\t\tshuffle=True, \n\t\t\t\t\t\t\t\tnum_workers=4)\n\t\t\t\t\t\t\t\t\ntest_loader = data.DataLoader(test_dataset,\n\t\t\t\t\t\t\t\tbatch_size=config.test_num_ng+1, \n\t\t\t\t\t\t\t\tshuffle=False, \n\t\t\t\t\t\t\t\tnum_workers=0)",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T09:09:26.616302Z",
     "iopub.status.busy": "2024-10-29T09:09:26.615979Z",
     "iopub.status.idle": "2024-10-29T09:09:28.100529Z",
     "shell.execute_reply": "2024-10-29T09:09:28.099713Z"
    },
    "papermill": {
     "duration": 1.490983,
     "end_time": "2024-10-29T09:09:28.102782",
     "exception": false,
     "start_time": "2024-10-29T09:09:26.611799",
     "status": "completed"
    },
    "tags": [],
    "trusted": false
   },
   "id": "811681dc",
   "cell_type": "code",
   "source": "if config.model == 'NeuMF-pre':\n\tassert os.path.exists(config.GMF_model_path), 'lack of GMF model'\n\tassert os.path.exists(config.MLP_model_path), 'lack of MLP model'\n\tGMF_model = torch.load(config.GMF_model_path)\n\tMLP_model = torch.load(config.MLP_model_path)\nelse:\n\tGMF_model = None\n\tMLP_model = None\n\nmodel = NCF(user_num, \n\t\t\titem_num, \n\t\t\tconfig.factor_num, \n\t\t\tconfig.num_layers, \n\t\t\tconfig.dropout, \n\t\t\tconfig.model, \n\t\t\tGMF_model, \n\t\t\tMLP_model)\n\t\t\t\nmodel.cuda()\nloss_function = nn.BCEWithLogitsLoss()\n\nif config.model == 'NeuMF-pre':\n\toptimizer = optim.SGD(model.parameters(), lr=config.lr)\nelse:\n\toptimizer = optim.Adam(model.parameters(), lr=config.lr)",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T09:09:28.110815Z",
     "iopub.status.busy": "2024-10-29T09:09:28.110385Z",
     "iopub.status.idle": "2024-10-29T09:49:32.668003Z",
     "shell.execute_reply": "2024-10-29T09:49:32.666728Z"
    },
    "papermill": {
     "duration": 2404.567866,
     "end_time": "2024-10-29T09:49:32.674138",
     "exception": false,
     "start_time": "2024-10-29T09:09:28.106272",
     "status": "completed"
    },
    "tags": [],
    "trusted": false
   },
   "id": "b3ec2859",
   "cell_type": "code",
   "source": "count, best_hr = 0, 0\nfor epoch in range(config.epochs):\n\tmodel.train() \n\tstart_time = time.time()\n\ttrain_loader.dataset.ng_sample()\n\n\tfor user, item, label in train_loader:\n\t\tuser = user.cuda()\n\t\titem = item.cuda()\n\t\tlabel = label.float().cuda()\n\n\t\tmodel.zero_grad()\n\t\tprediction = model(user, item)\n\t\tloss = loss_function(prediction, label)\n\t\tloss.backward()\n\t\toptimizer.step()\n\t\tcount += 1\n\n\tmodel.eval()\n\tHR, NDCG = metrics(model, test_loader, config.top_k)\n\n\telapsed_time = time.time() - start_time\n\tprint(\"The time elapse of epoch {:03d}\".format(epoch) + \" is: \" + \n\t\t\ttime.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n\tprint(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG)))\n\n\tif HR > best_hr:\n\t\tbest_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n\t\tif config.out:\n\t\t\tif not os.path.exists(config.model_path):\n\t\t\t\tos.mkdir(config.model_path)\n\t\t\ttorch.save(model, \n\t\t\t\t'{}{}.pth'.format(config.model_path, config.model))\n\nprint(\"End. Best epoch {:03d}: HR = {:.3f}, NDCG = {:.3f}\".format(\n\t\t\t\t\t\t\t\t\tbest_epoch, best_hr, best_ndcg))",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The time elapse of epoch 000 is: 00: 02: 01\nHR: 0.629\tNDCG: 0.366\nThe time elapse of epoch 001 is: 00: 02: 00\nHR: 0.670\tNDCG: 0.397\nThe time elapse of epoch 002 is: 00: 02: 01\nHR: 0.686\tNDCG: 0.411\nThe time elapse of epoch 003 is: 00: 02: 00\nHR: 0.685\tNDCG: 0.410\nThe time elapse of epoch 004 is: 00: 01: 59\nHR: 0.698\tNDCG: 0.419\nThe time elapse of epoch 005 is: 00: 02: 01\nHR: 0.702\tNDCG: 0.425\nThe time elapse of epoch 006 is: 00: 01: 59\nHR: 0.700\tNDCG: 0.423\nThe time elapse of epoch 007 is: 00: 02: 01\nHR: 0.698\tNDCG: 0.418\nThe time elapse of epoch 008 is: 00: 01: 59\nHR: 0.699\tNDCG: 0.422\nThe time elapse of epoch 009 is: 00: 02: 01\nHR: 0.699\tNDCG: 0.423\nThe time elapse of epoch 010 is: 00: 01: 59\nHR: 0.698\tNDCG: 0.422\nThe time elapse of epoch 011 is: 00: 02: 01\nHR: 0.691\tNDCG: 0.420\nThe time elapse of epoch 012 is: 00: 01: 59\nHR: 0.695\tNDCG: 0.420\nThe time elapse of epoch 013 is: 00: 02: 00\nHR: 0.691\tNDCG: 0.416\nThe time elapse of epoch 014 is: 00: 01: 58\nHR: 0.693\tNDCG: 0.418\nThe time elapse of epoch 015 is: 00: 01: 59\nHR: 0.688\tNDCG: 0.417\nThe time elapse of epoch 016 is: 00: 01: 58\nHR: 0.683\tNDCG: 0.413\nThe time elapse of epoch 017 is: 00: 02: 00\nHR: 0.678\tNDCG: 0.410\nThe time elapse of epoch 018 is: 00: 01: 59\nHR: 0.681\tNDCG: 0.414\nThe time elapse of epoch 019 is: 00: 01: 59\nHR: 0.676\tNDCG: 0.407\nEnd. Best epoch 005: HR = 0.702, NDCG = 0.425\n"
    }
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5864890,
     "sourceId": 9611543,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2435.87021,
   "end_time": "2024-10-29T09:49:35.297856",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-29T09:08:59.427646",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}