{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Линейная регрессия Практика\n\n### <b><span style='color:#686dec'>Предсказания Стоимости Дома</span></b>\n\n#### Данные из Бостона\n\nВ следующих заданиях будет использоваться датасет boston из `sklearn.datasets`"
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_boston\nfrom sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt",
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Загружаем датасет про цены домов в Бостоне\n- Нам нужно предсказать медиану цены жилья в 506 районах"
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "data = load_boston()\ndata['data'].shape",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "(506, 13)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <b><span style='color:#686dec'>Использованием матричных операций</span></b>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Линейная регрессия выражается следующей зависимостью:\n$$y=X\\theta+\\epsilon,$$\nгде \n- $X$ — матрица объекты-признаки\n- $y$ — вектор целевых значений, \n\nсоответствующих:\n- $X$, $\\theta$ — параметр линейной регрессии, $\\epsilon$ — некоторый шум.\n\nИз данного следует выражение для $\\theta$ как:\n$$X^Ty=X^TX\\theta \\rightarrow \\theta=(X^TX)^{-1}X^Ty$$\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Реализуем выражение для $\\theta$ с помощью операций линейной алгебры библиотеки Numpy:"
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "from numpy.linalg import inv\n\n# ЗАДАЧА Реализовать функцию, осуществляющую матричные операции для получения theta\ndef linreg_linear(X, y):\n    lsm = inv(np.dot(X.T,X))\n    Xt = np.dot(X.T,y)\n    theta = np.dot(lsm,Xt)\n    return theta",
   "execution_count": 38,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Используем одну выборку "
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "# Подготовить данные\n\nX, y = data['data'], data['target']\n\nX = np.hstack([np.ones(X.shape[0])[:,None], X])\nprint(X.shape)",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(506, 14)\n"
    }
   ]
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "# Вычислить параметр theta\ntheta = linreg_linear(X, y)\nprint(theta)",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[ 3.64594884e+01 -1.08011358e-01  4.64204584e-02  2.05586264e-02\n  2.68673382e+00 -1.77666112e+01  3.80986521e+00  6.92224640e-04\n -1.47556685e+00  3.06049479e-01 -1.23345939e-02 -9.52747232e-01\n  9.31168327e-03 -5.24758378e-01]\n"
    }
   ]
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "theta.shape",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "(14,)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "# Сделать предсказания для тренировочной выборки\ny_pred = X.dot(theta)",
   "execution_count": 42,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "def print_regression_metrics(y_true, y_pred):\n    mse = mean_squared_error(y_true, y_pred)\n    rmse = np.sqrt(mse)\n    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')",
   "execution_count": 43,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Посчитать значение ошибок MSE и RMSE для тренировочных данных"
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "print_regression_metrics(y, y_pred)",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "MSE = 21.89, RMSE = 4.68\n"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Проверим обобщающию способность модели\n\n- Мы обучили модель на некой выборке, и на них же посчитали метрику качества \n- Мы не проверили обобщающию способность модели"
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "plt.hist(y);",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 480x360 with 1 Axes>"
     },
     "metadata": {
      "image/png": {
       "height": 323,
       "width": 428
      }
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "# Разбить выборку на train/valid, вычислить theta,\n# сделать предсказания и посчитать ошибки MSE и RMSE\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\ntheta = linreg_linear(X_train, y_train)\ny_pred = X_valid.dot(theta)\ny_train_pred = X_train.dot(theta)",
   "execution_count": 46,
   "outputs": []
  },
  {
   "metadata": {
    "scrolled": true,
    "trusted": false
   },
   "cell_type": "code",
   "source": "print_regression_metrics(y_valid, y_pred)\nprint_regression_metrics(y_train, y_train_pred)",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "MSE = 19.20, RMSE = 4.38\nMSE = 22.80, RMSE = 4.77\n"
    }
   ]
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "from sklearn.linear_model import LinearRegression\n:\nlr = LinearRegression()\nlr.fit(X,y)\ny_pred = lr.predict(X)\nprint_regression_metrics(y, y_pred)",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "MSE = 21.89, RMSE = 4.68\n"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <b><span style='color:#686dec'>Использованием методов оптимизации (Градиентный Спуск)</span></b>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Для реализации линейной регрессии с помощью методов оптимизации будем использовать функцию ошибки **среднего квадратичного** ([Mean Squared Error](https://en.wikipedia.org/wiki/Mean_squared_error)), которая является выпуклой функцией в n-мерном пространстве $\\mathbb{R}^n$ и в общем виде выглядит следующим образом:\n$$MSE = \\frac{1}{n} * \\sum_{i=1}^{n}{(y_i - a(x_i))^2}.$$\nЗдесь $x_i$ — вектор-признак $i$-го объекта обучающей выборки, $y_i$ — истинное значение для $i$-го объекта, $a(x)$ — алгоритм, предсказывающий для данного объекта $x$ целевое значение, $n$ — кол-во объектов в выборке."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "В случае линейной регрессии $MSE$ представляется как:\n$$MSE(X, y, \\theta) = \\frac{1}{2n} * \\sum_{i=1}^{n}{(y_i - \\theta^Tx_i)^2} = \\frac{1}{2n} \\lVert{y - X\\theta}\\rVert_{2}^{2}=\\frac{1}{2n} (y - X\\theta)^T(y - X\\theta),$$\nгде $\\theta$ — параметр модели линейной регрессии, $X$ — матрица объекты-признаки, $y$ - вектор истинных значений, соответствующих $X$."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Возьмем первый вариант представления функции ошибки и посчитаем ее градиент по параметру $\\theta$, предварительно переименовав $MSE$ в $L$:\n$$L=\\frac{1}{2n} * \\sum_{i=1}^{n}{(y_i - \\theta^Tx_i)^2}$$\n$$\\nabla L = \\frac{1}{n}\\sum_{i=1}^{n}{(\\theta^Tx_i - y_i) \\cdot x_i} = \\frac{1}{n}X^T(X\\theta - y)$$"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Исходя из полученного выражения градиента, реализуем алгоритм градиентного спуска:"
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "from tqdm.notebook import tqdm\n\n# вычисления градиента функции MSE\n\ndef calc_mse_gradient(X, y, theta):\n    n = X.shape[0]\n    grad = (1.0/n) * X.T.dot(X.dot(theta) - y)\n    return grad\n\n# Шаг градиентного спуска  \n\ndef gradient_step(theta, theta_grad, alpha):\n    return theta - alpha * theta_grad\n\n# Процедура оптимизации\n\ndef optimize(X, y, grad_func, start_theta, alpha, n_iters):\n    \n    # начальное theta\n    theta = start_theta.copy()\n    \n    for i in tqdm(range(n_iters)):\n        theta_grad = grad_func(X, y, theta)\n        theta = gradient_step(theta, theta_grad, alpha)\n    \n    return theta\n",
   "execution_count": 49,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "# Разбить таблицу данных на матрицы X и y\nX, y = data['data'], data['target']\n\n# Добавить фиктивный столбец единиц (bias линейной модели)\nX = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\nm = X.shape[1]",
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "# Оптимизировать параметр линейной регрессии theta на всех данных\ntheta = optimize(X, y, calc_mse_gradient, np.ones(m), 0.001, 100)",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e68726a2494573b78541a1ba643db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "theta",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "array([7.41647399e+246, 3.32349992e+247, 7.39564172e+247, 8.96295209e+247,\n       5.07578059e+245, 4.22030567e+246, 4.63094053e+247, 5.29083888e+248,\n       2.65643383e+247, 8.19991211e+247, 3.27135991e+249, 1.38363846e+248,\n       2.64323053e+249, 9.88835598e+247])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "# Проверить максимальные значения по каждому признаку в данных\nX.max(axis=0)",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "array([  1.    ,  88.9762, 100.    ,  27.74  ,   1.    ,   0.871 ,\n         8.78  , 100.    ,  12.1265,  24.    , 711.    ,  22.    ,\n       396.9   ,  37.97  ])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "print(data['feature_names'][np.argmax(X.std(axis=0)) + 1])\nprint(np.max(X.std(axis=0)))",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "B\n168.3704950393814\n"
    }
   ]
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "# Нормализовать даннные с помощью стандартной нормализации\nX, y = data['data'], data['target']\nX = (X - X.mean(axis=0)) / X.std(axis=0)",
   "execution_count": 55,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "# Добавить фиктивный столбец единиц (bias линейной модели)\nX = np.hstack([np.ones(X.shape[0])[:,None], X])\nX.max(axis=0)",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1.        , 9.9339306 , 3.80423444, 2.42256516, 3.66839786,\n       2.73234648, 3.55504427, 1.11749449, 3.96051769, 1.66124525,\n       1.79819419, 1.63882832, 0.44105193, 3.54877081])"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "# Оптимизировать theta на новых данных\ntheta = optimize(X, y, calc_mse_gradient, np.ones(m), 0.01, 5000)",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4f307be0ad463890696199c096b5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/5000 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "theta",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 2.25328063e+01, -9.21740195e-01,  1.07033639e+00,  1.06388396e-01,\n        6.86667316e-01, -2.05006416e+00,  2.68062168e+00,  1.40667969e-02,\n       -3.10608483e+00,  2.57511475e+00, -1.97802851e+00, -2.05725099e+00,\n        8.48690321e-01, -3.74025884e+00])"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "# Сделать предсказания при полученных параметрах\ny_pred = X.dot(theta)",
   "execution_count": 59,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "# Посчитать значение ошибок MSE и RMSE для тренировочных данных\nprint_regression_metrics(y, y_pred)",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "MSE = 21.90, RMSE = 4.68\n"
    }
   ]
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "# Разбить выборку на train/valid, оптимизировать theta,\n# сделать предсказания и посчитать ошибки MSE и RMSE\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\ntheta = optimize(X_train, y_train, calc_mse_gradient, np.ones(m), 0.01, 5000)\ny_pred = X_valid.dot(theta)\n\nprint_regression_metrics(y_valid, y_pred)",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc89917b909a4948865a28e122e0dfb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/5000 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "MSE = 20.05, RMSE = 4.48\n"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <b><span style='color:#686dec'>Задание</span></b>\n\n#### <b>Задание <span style='color:#686dec'>3.6.1</span></b> \n\n\nРеализуйте матричную линейную регрессию. Какой получился RMSE?\n\n4.68 (уже выполненно)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### <b>Задание <span style='color:#686dec'>3.6.2</span></b> \n\n\nПостройте модель при помощи sklearn. Используйте параметры по умолчанию, обучите на всей выборке и посчитайте RMSE."
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "from sklearn.linear_model import LinearRegression as LR\n\nX, y = data['data'], data['target']\nX = np.hstack([np.ones(X.shape[0])[:,None], X])\n\nmodel = LR()\nmodel.fit(X,y)\ny_pred = model.predict(X)\n\nprint_regression_metrics(y, y_pred)",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "MSE = 21.89, RMSE = 4.68\n"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### <b>Задание <span style='color:#686dec'>3.6.3</span></b> \n\n\nУ какого из признаков наибольшее стандартное отклонение? Чему оно равно?"
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "df = pd.DataFrame(data['data'],columns=data['feature_names'])\ndf.head()",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>B</th>\n      <th>LSTAT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00632</td>\n      <td>18.0</td>\n      <td>2.31</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>6.575</td>\n      <td>65.2</td>\n      <td>4.0900</td>\n      <td>1.0</td>\n      <td>296.0</td>\n      <td>15.3</td>\n      <td>396.90</td>\n      <td>4.98</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02731</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>6.421</td>\n      <td>78.9</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>396.90</td>\n      <td>9.14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02729</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>7.185</td>\n      <td>61.1</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>392.83</td>\n      <td>4.03</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.03237</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>6.998</td>\n      <td>45.8</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>394.63</td>\n      <td>2.94</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.06905</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>7.147</td>\n      <td>54.2</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>396.90</td>\n      <td>5.33</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "      CRIM    ZN  INDUS  CHAS    NOX  ...  RAD    TAX  PTRATIO       B  LSTAT\n0  0.00632  18.0   2.31   0.0  0.538  ...  1.0  296.0     15.3  396.90   4.98\n1  0.02731   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  396.90   9.14\n2  0.02729   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  392.83   4.03\n3  0.03237   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  394.63   2.94\n4  0.06905   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  396.90   5.33\n\n[5 rows x 13 columns]"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "df.describe()",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>B</th>\n      <th>LSTAT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.613524</td>\n      <td>11.363636</td>\n      <td>11.136779</td>\n      <td>0.069170</td>\n      <td>0.554695</td>\n      <td>6.284634</td>\n      <td>68.574901</td>\n      <td>3.795043</td>\n      <td>9.549407</td>\n      <td>408.237154</td>\n      <td>18.455534</td>\n      <td>356.674032</td>\n      <td>12.653063</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.601545</td>\n      <td>23.322453</td>\n      <td>6.860353</td>\n      <td>0.253994</td>\n      <td>0.115878</td>\n      <td>0.702617</td>\n      <td>28.148861</td>\n      <td>2.105710</td>\n      <td>8.707259</td>\n      <td>168.537116</td>\n      <td>2.164946</td>\n      <td>91.294864</td>\n      <td>7.141062</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.006320</td>\n      <td>0.000000</td>\n      <td>0.460000</td>\n      <td>0.000000</td>\n      <td>0.385000</td>\n      <td>3.561000</td>\n      <td>2.900000</td>\n      <td>1.129600</td>\n      <td>1.000000</td>\n      <td>187.000000</td>\n      <td>12.600000</td>\n      <td>0.320000</td>\n      <td>1.730000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.082045</td>\n      <td>0.000000</td>\n      <td>5.190000</td>\n      <td>0.000000</td>\n      <td>0.449000</td>\n      <td>5.885500</td>\n      <td>45.025000</td>\n      <td>2.100175</td>\n      <td>4.000000</td>\n      <td>279.000000</td>\n      <td>17.400000</td>\n      <td>375.377500</td>\n      <td>6.950000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.256510</td>\n      <td>0.000000</td>\n      <td>9.690000</td>\n      <td>0.000000</td>\n      <td>0.538000</td>\n      <td>6.208500</td>\n      <td>77.500000</td>\n      <td>3.207450</td>\n      <td>5.000000</td>\n      <td>330.000000</td>\n      <td>19.050000</td>\n      <td>391.440000</td>\n      <td>11.360000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.677083</td>\n      <td>12.500000</td>\n      <td>18.100000</td>\n      <td>0.000000</td>\n      <td>0.624000</td>\n      <td>6.623500</td>\n      <td>94.075000</td>\n      <td>5.188425</td>\n      <td>24.000000</td>\n      <td>666.000000</td>\n      <td>20.200000</td>\n      <td>396.225000</td>\n      <td>16.955000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>88.976200</td>\n      <td>100.000000</td>\n      <td>27.740000</td>\n      <td>1.000000</td>\n      <td>0.871000</td>\n      <td>8.780000</td>\n      <td>100.000000</td>\n      <td>12.126500</td>\n      <td>24.000000</td>\n      <td>711.000000</td>\n      <td>22.000000</td>\n      <td>396.900000</td>\n      <td>37.970000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "             CRIM          ZN       INDUS  ...     PTRATIO           B       LSTAT\ncount  506.000000  506.000000  506.000000  ...  506.000000  506.000000  506.000000\nmean     3.613524   11.363636   11.136779  ...   18.455534  356.674032   12.653063\nstd      8.601545   23.322453    6.860353  ...    2.164946   91.294864    7.141062\nmin      0.006320    0.000000    0.460000  ...   12.600000    0.320000    1.730000\n25%      0.082045    0.000000    5.190000  ...   17.400000  375.377500    6.950000\n50%      0.256510    0.000000    9.690000  ...   19.050000  391.440000   11.360000\n75%      3.677083   12.500000   18.100000  ...   20.200000  396.225000   16.955000\nmax     88.976200  100.000000   27.740000  ...   22.000000  396.900000   37.970000\n\n[8 rows x 13 columns]"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "X, y = data['data'], data['target']\n\nprint(data.feature_names)\nprint(X.std(axis=0))",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n 'B' 'LSTAT']\n[8.59304135e+00 2.32993957e+01 6.85357058e+00 2.53742935e-01\n 1.15763115e-01 7.01922514e-01 2.81210326e+01 2.10362836e+00\n 8.69865112e+00 1.68370495e+02 2.16280519e+00 9.12046075e+01\n 7.13400164e+00]\n"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### <b>Задание <span style='color:#686dec'>3.6.4</span></b> \n\n\nОбучите регрессию без дополнительного столбца единиц. Какой получился RMSE?"
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "X, y = data['data'], data['target']\n\nmodel = LR()\nmodel.fit(X,y)\ny_pred = model.predict(X)\n\nprint_regression_metrics(y, y_pred)",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "MSE = 21.89, RMSE = 4.68\n"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### <b>Задание <span style='color:#686dec'>3.6.5</span></b> \n\n\nОчистите данные от строк, где значение признака  меньше . Какой получился RMSE?"
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "df = pd.DataFrame(data['data'],columns=data['feature_names'])\ndfy = pd.DataFrame(data['target'],columns=['target'])\ndf_all = pd.concat([df,dfy],axis=1)\n\nldf = df_all[~(df_all['B'] < 50)]\nldf.head()",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>B</th>\n      <th>LSTAT</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00632</td>\n      <td>18.0</td>\n      <td>2.31</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>6.575</td>\n      <td>65.2</td>\n      <td>4.0900</td>\n      <td>1.0</td>\n      <td>296.0</td>\n      <td>15.3</td>\n      <td>396.90</td>\n      <td>4.98</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02731</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>6.421</td>\n      <td>78.9</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>396.90</td>\n      <td>9.14</td>\n      <td>21.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02729</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>7.185</td>\n      <td>61.1</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>392.83</td>\n      <td>4.03</td>\n      <td>34.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.03237</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>6.998</td>\n      <td>45.8</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>394.63</td>\n      <td>2.94</td>\n      <td>33.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.06905</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>7.147</td>\n      <td>54.2</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>396.90</td>\n      <td>5.33</td>\n      <td>36.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  target\n0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98    24.0\n1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14    21.6\n2  0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03    34.7\n3  0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94    33.4\n4  0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33    36.2\n\n[5 rows x 14 columns]"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "y = ldf['target']\nX = ldf.drop(['target'],axis=1)\n\nX = np.hstack([np.ones(X.shape[0])[:,None], X])\n\nmodel = LR()\nmodel.fit(X,y)\ny_pred = model.predict(X)\n\nprint_regression_metrics(y, y_pred)",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "MSE = 21.79, RMSE = 4.67\n"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### <b>Задание <span style='color:#686dec'>3.6.6</span></b> \n\n\nНормализуйте признаки и обучите линейную регрессию матричным методом. Какой получился RMSE?"
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "# Разбить таблицу данных на матрицы X и y\nX, y = data['data'], data['target']\nX = (X - X.mean(axis=0)) / X.std(axis=0)\n\n# Добавить фиктивный столбец единиц (bias линейной модели)\nX = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])",
   "execution_count": 70,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "def linreg_linear(X, y):\n    lsm = inv(np.dot(X.T,X))\n    Xt = np.dot(X.T,y)\n    theta = np.dot(lsm,Xt)\n    return theta\n\ntheta = linreg_linear(X,y)\ny_pred = X.dot(theta)\n\nprint_regression_metrics(y, y_pred)",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "MSE = 21.89, RMSE = 4.68\n"
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}